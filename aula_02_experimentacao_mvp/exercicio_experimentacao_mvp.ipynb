{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 2: Experimentação e MVP de Modelos\n",
    "\n",
    "## Objetivos de Aprendizagem\n",
    "- Configurar e usar MLFlow para rastreamento de experimentos\n",
    "- Experimentar com diferentes algoritmos e hiperparâmetros\n",
    "- Comparar resultados de múltiplos experimentos\n",
    "- Criar um MVP (Minimum Viable Product) de modelo\n",
    "\n",
    "## Exercício Prático\n",
    "Você trabalhará com um dataset de classificação e realizará experimentos com diferentes modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset\n",
    "wine = load_wine()\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "y = wine.target\n",
    "\n",
    "print(f\"Shape dos dados: {X.shape}\")\n",
    "print(f\"Classes: {np.unique(y)}\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Normalizar dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Treino: {X_train.shape}, Teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuração do MLFlow\n",
    "\n",
    "### Tarefa 1: Configure o MLFlow para rastrear seus experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar experimento do MLFlow\n",
    "mlflow.set_experiment(\"wine_classification_experiments\")\n",
    "\n",
    "# Iniciar UI do MLFlow (opcional - executar em terminal separado)\n",
    "# mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experimento 1: Regressão Logística\n",
    "\n",
    "### Tarefa 2: Treine um modelo de Regressão Logística e registre no MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"logistic_regression_baseline\"):\n",
    "    # Parâmetros\n",
    "    max_iter = 1000\n",
    "    C = 1.0\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model = LogisticRegression(max_iter=max_iter, C=C, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Registrar parâmetros\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    mlflow.log_param(\"C\", C)\n",
    "    \n",
    "    # Registrar métricas\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    \n",
    "    # Registrar modelo\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    print(f\"Logistic Regression - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experimento 2: Árvore de Decisão\n",
    "\n",
    "### Tarefa 3: Experimente com diferentes profundidades de árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentar com diferentes profundidades\n",
    "max_depths = [3, 5, 10, None]\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    with mlflow.start_run(run_name=f\"decision_tree_depth_{max_depth}\"):\n",
    "        # Treinar modelo\n",
    "        model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Fazer previsões\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # Registrar parâmetros e métricas\n",
    "        mlflow.log_param(\"model_type\", \"DecisionTree\")\n",
    "        mlflow.log_param(\"max_depth\", max_depth if max_depth else \"None\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        # Registrar modelo\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"Decision Tree (depth={max_depth}) - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Experimento 3: Random Forest\n",
    "\n",
    "### Tarefa 4: Otimize hiperparâmetros do Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentar com diferentes configurações\n",
    "configs = [\n",
    "    {\"n_estimators\": 50, \"max_depth\": 5},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 10},\n",
    "    {\"n_estimators\": 200, \"max_depth\": None},\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    with mlflow.start_run(run_name=f\"random_forest_{config['n_estimators']}_trees\"):\n",
    "        # Treinar modelo\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=config[\"n_estimators\"],\n",
    "            max_depth=config[\"max_depth\"],\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Fazer previsões\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # Registrar parâmetros e métricas\n",
    "        mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "        mlflow.log_param(\"n_estimators\", config[\"n_estimators\"])\n",
    "        mlflow.log_param(\"max_depth\", config[\"max_depth\"] if config[\"max_depth\"] else \"None\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        \n",
    "        # Registrar modelo\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"Random Forest ({config['n_estimators']} trees) - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparação de Experimentos\n",
    "\n",
    "### Tarefa 5: Compare os resultados de todos os experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar todos os runs do experimento\n",
    "experiment = mlflow.get_experiment_by_name(\"wine_classification_experiments\")\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "# Visualizar resultados\n",
    "print(\"\\n=== COMPARAÇÃO DE EXPERIMENTOS ===\")\n",
    "print(runs[['tags.mlflow.runName', 'metrics.accuracy', 'metrics.f1_score']].sort_values(\n",
    "    by='metrics.accuracy', ascending=False\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Seleção do Melhor Modelo (MVP)\n",
    "\n",
    "### Tarefa 6: Selecione e registre o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar o melhor run\n",
    "best_run = runs.loc[runs['metrics.accuracy'].idxmax()]\n",
    "best_run_id = best_run['run_id']\n",
    "\n",
    "print(f\"\\nMelhor Modelo:\")\n",
    "print(f\"Run Name: {best_run['tags.mlflow.runName']}\")\n",
    "print(f\"Accuracy: {best_run['metrics.accuracy']:.4f}\")\n",
    "print(f\"F1 Score: {best_run['metrics.f1_score']:.4f}\")\n",
    "print(f\"Run ID: {best_run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exercícios Adicionais\n",
    "\n",
    "### Desafios para Praticar:\n",
    "\n",
    "1. **Adicione mais modelos**: Experimente com SVM, KNN ou Gradient Boosting\n",
    "2. **Validação Cruzada**: Implemente cross-validation e registre as métricas médias\n",
    "3. **Feature Importance**: Para modelos baseados em árvores, registre a importância das features\n",
    "4. **Gráficos**: Crie gráficos de comparação e salve como artifacts no MLFlow\n",
    "5. **Tags**: Use tags do MLFlow para organizar seus experimentos (ex: \"production_candidate\")\n",
    "\n",
    "### Questões para Reflexão:\n",
    "\n",
    "1. Qual modelo teve o melhor desempenho? Por quê?\n",
    "2. Existe evidência de overfitting em algum modelo?\n",
    "3. Como você escolheria entre um modelo com maior accuracy e um com melhor F1 score?\n",
    "4. Quais outros experimentos você faria antes de colocar o modelo em produção?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Acessando o MLFlow UI\n",
    "\n",
    "Para visualizar seus experimentos graficamente:\n",
    "\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "Depois acesse http://localhost:5000 no seu navegador."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
