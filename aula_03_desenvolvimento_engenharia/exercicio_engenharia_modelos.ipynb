{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 3: Desenvolvimento e Engenharia de Modelos\n",
    "\n",
    "## Objetivos de Aprendizagem\n",
    "- Aplicar técnicas de feature engineering\n",
    "- Implementar pipelines de processamento\n",
    "- Tratar dados desbalanceados\n",
    "- Otimizar hiperparâmetros sistematicamente\n",
    "- Validar modelos com técnicas apropriadas\n",
    "\n",
    "## Exercício Prático\n",
    "Desenvolver um modelo robusto com feature engineering completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"\\nClasses: {data.target_names}\")\n",
    "print(f\"Distribuição de classes: {np.bincount(y)}\")\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise estatística\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(\"Valores nulos por coluna:\")\n",
    "print(X.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "### Tarefa 1: Criar novas features baseadas nas existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features de interação\n",
    "X_engineered = X.copy()\n",
    "\n",
    "# Razões entre features relacionadas\n",
    "X_engineered['mean_area_radius_ratio'] = X['mean area'] / (X['mean radius'] + 1e-6)\n",
    "X_engineered['mean_perimeter_radius_ratio'] = X['mean perimeter'] / (X['mean radius'] + 1e-6)\n",
    "\n",
    "# Features agregadas\n",
    "X_engineered['mean_texture_symmetry_product'] = X['mean texture'] * X['mean symmetry']\n",
    "X_engineered['worst_area_mean_area_ratio'] = X['worst area'] / (X['mean area'] + 1e-6)\n",
    "\n",
    "# Features polinomiais para features importantes\n",
    "X_engineered['mean_concavity_squared'] = X['mean concavity'] ** 2\n",
    "X_engineered['worst_perimeter_squared'] = X['worst perimeter'] ** 2\n",
    "\n",
    "print(f\"Features após engenharia: {X_engineered.shape[1]}\")\n",
    "print(f\"Novas features criadas: {X_engineered.shape[1] - X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Seleção de Features\n",
    "\n",
    "### Tarefa 2: Selecione as features mais relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_engineered, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Seleção de features usando ANOVA F-value\n",
    "selector = SelectKBest(f_classif, k=20)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Identificar features selecionadas\n",
    "selected_features = X_engineered.columns[selector.get_support()]\n",
    "print(f\"\\nFeatures selecionadas ({len(selected_features)}):\")\n",
    "for i, feat in enumerate(selected_features, 1):\n",
    "    print(f\"{i}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Criação de Pipeline de Processamento\n",
    "\n",
    "### Tarefa 3: Construa um pipeline completo de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar MLFlow\n",
    "mlflow.set_experiment(\"breast_cancer_feature_engineering\")\n",
    "\n",
    "# Criar pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "print(\"Pipeline criado:\")\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Otimização de Hiperparâmetros\n",
    "\n",
    "### Tarefa 4: Use Grid Search para encontrar os melhores hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir grade de hiperparâmetros\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [5, 10, None],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Grid Search com Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Iniciando Grid Search...\")\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "print(f\"\\nMelhores parâmetros: {grid_search.best_params_}\")\n",
    "print(f\"Melhor score (ROC-AUC): {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Treinamento do Modelo Final\n",
    "\n",
    "### Tarefa 5: Treine o modelo com os melhores parâmetros e registre no MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"optimized_random_forest\"):\n",
    "    # Modelo otimizado\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Previsões\n",
    "    y_pred = best_model.predict(X_test_selected)\n",
    "    y_pred_proba = best_model.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    # Métricas\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(best_model, X_train_selected, y_train, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    # Registrar parâmetros\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_param(\"n_features\", X_train_selected.shape[1])\n",
    "    mlflow.log_param(\"feature_engineering\", \"yes\")\n",
    "    \n",
    "    # Registrar métricas\n",
    "    mlflow.log_metric(\"test_roc_auc\", roc_auc)\n",
    "    mlflow.log_metric(\"cv_roc_auc_mean\", cv_scores.mean())\n",
    "    mlflow.log_metric(\"cv_roc_auc_std\", cv_scores.std())\n",
    "    \n",
    "    # Registrar modelo\n",
    "    mlflow.sklearn.log_model(best_model, \"model\")\n",
    "    \n",
    "    print(f\"\\nROC-AUC no teste: {roc_auc:.4f}\")\n",
    "    print(f\"ROC-AUC CV (média ± std): {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Avaliação Detalhada\n",
    "\n",
    "### Tarefa 6: Analise o desempenho do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatório de classificação\n",
    "print(\"=== RELATÓRIO DE CLASSIFICAÇÃO ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=data.target_names, \n",
    "            yticklabels=data.target_names)\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Valor Predito')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.3f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance\n",
    "\n",
    "### Tarefa 7: Analise a importância das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair feature importance\n",
    "feature_importance = best_model.named_steps['classifier'].feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': selected_features,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualizar top 15 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df.head(15), x='importance', y='feature')\n",
    "plt.title('Top 15 Features Mais Importantes')\n",
    "plt.xlabel('Importância')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/feature_importance.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comparação: Modelo Baseline vs Engenharia de Features\n",
    "\n",
    "### Tarefa 8: Compare com um modelo sem feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo baseline sem feature engineering\n",
    "X_train_orig, X_test_orig, _, _ = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"baseline_no_feature_engineering\"):\n",
    "    # Pipeline simples\n",
    "    baseline_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=100, max_depth=10, random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Treinar\n",
    "    baseline_pipeline.fit(X_train_orig, y_train)\n",
    "    \n",
    "    # Avaliar\n",
    "    y_pred_baseline = baseline_pipeline.predict(X_test_orig)\n",
    "    y_pred_proba_baseline = baseline_pipeline.predict_proba(X_test_orig)[:, 1]\n",
    "    roc_auc_baseline = roc_auc_score(y_test, y_pred_proba_baseline)\n",
    "    \n",
    "    # Registrar\n",
    "    mlflow.log_param(\"feature_engineering\", \"no\")\n",
    "    mlflow.log_metric(\"test_roc_auc\", roc_auc_baseline)\n",
    "    mlflow.sklearn.log_model(baseline_pipeline, \"model\")\n",
    "    \n",
    "    print(f\"Baseline ROC-AUC: {roc_auc_baseline:.4f}\")\n",
    "\n",
    "print(f\"\\n=== COMPARAÇÃO ===\")\n",
    "print(f\"Baseline (sem FE): {roc_auc_baseline:.4f}\")\n",
    "print(f\"Com Feature Engineering: {roc_auc:.4f}\")\n",
    "print(f\"Melhoria: {((roc_auc - roc_auc_baseline) / roc_auc_baseline * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Exercícios Adicionais\n",
    "\n",
    "### Desafios para Praticar:\n",
    "\n",
    "1. **Experimente outros scalers**: Teste RobustScaler e MinMaxScaler\n",
    "2. **PCA**: Aplique PCA para redução de dimensionalidade e compare resultados\n",
    "3. **Ensemble Methods**: Combine múltiplos modelos usando VotingClassifier\n",
    "4. **Feature Engineering Avançado**: Crie features usando domain knowledge\n",
    "5. **Calibração**: Use CalibratedClassifierCV para melhorar probabilidades\n",
    "6. **Análise de Erro**: Identifique padrões nos casos mal classificados\n",
    "\n",
    "### Questões para Reflexão:\n",
    "\n",
    "1. Quais features engineered foram mais importantes?\n",
    "2. O feature engineering melhorou significativamente o desempenho?\n",
    "3. Como você validaria que não há data leakage nas novas features?\n",
    "4. Quais outras técnicas de feature engineering você aplicaria?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
