{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 4: Implantação de Modelos (Deployment)\n",
    "\n",
    "## Objetivos de Aprendizagem\n",
    "- Registrar modelos no MLFlow Model Registry\n",
    "- Versionar modelos adequadamente\n",
    "- Servir modelos via API REST\n",
    "- Implementar estratégias de deployment\n",
    "- Criar endpoints de inferência\n",
    "\n",
    "## Exercício Prático\n",
    "Implantar um modelo de ML em produção usando MLFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparação do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import json\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Treinamento do Modelo para Deployment\n",
    "\n",
    "### Tarefa 1: Treine um modelo pronto para produção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Dados de treino: {X_train.shape}\")\n",
    "print(f\"Dados de teste: {X_test.shape}\")\n",
    "print(f\"Classes: {iris.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar experimento\n",
    "mlflow.set_experiment(\"iris_deployment\")\n",
    "\n",
    "# Treinar modelo com assinatura\n",
    "with mlflow.start_run(run_name=\"production_model_v1\") as run:\n",
    "    # Pipeline de ML\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Treinar\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Avaliar\n",
    "    train_score = pipeline.score(X_train, y_train)\n",
    "    test_score = pipeline.score(X_test, y_test)\n",
    "    \n",
    "    # Inferir assinatura do modelo\n",
    "    signature = infer_signature(X_train, pipeline.predict(X_train))\n",
    "    \n",
    "    # Criar exemplo de input\n",
    "    input_example = X_train.iloc[:5]\n",
    "    \n",
    "    # Registrar parâmetros e métricas\n",
    "    mlflow.log_params({\n",
    "        \"model_type\": \"RandomForest\",\n",
    "        \"n_estimators\": 100,\n",
    "        \"n_features\": X_train.shape[1]\n",
    "    })\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": train_score,\n",
    "        \"test_accuracy\": test_score\n",
    "    })\n",
    "    \n",
    "    # Registrar modelo com assinatura e exemplo\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline,\n",
    "        \"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=\"iris_classifier\"\n",
    "    )\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    print(f\"\\nModelo treinado!\")\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Train Accuracy: {train_score:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gerenciamento de Modelos no Registry\n",
    "\n",
    "### Tarefa 2: Promova o modelo para diferentes estágios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter cliente do MLFlow\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Listar versões do modelo\n",
    "model_name = \"iris_classifier\"\n",
    "versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "print(f\"Versões do modelo '{model_name}':\")\n",
    "for version in versions:\n",
    "    print(f\"  Versão {version.version}: Stage = {version.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promover modelo para Staging\n",
    "latest_version = versions[0].version\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=latest_version,\n",
    "    stage=\"Staging\",\n",
    "    archive_existing_versions=False\n",
    ")\n",
    "\n",
    "print(f\"Modelo versão {latest_version} promovido para Staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar descrição e tags ao modelo\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=latest_version,\n",
    "    description=\"Modelo de classificação de Iris - Versão inicial para staging\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=model_name,\n",
    "    version=latest_version,\n",
    "    key=\"validation_status\",\n",
    "    value=\"passed\"\n",
    ")\n",
    "\n",
    "print(\"Metadados atualizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Carregamento de Modelos para Inferência\n",
    "\n",
    "### Tarefa 3: Carregue e teste o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo do registry (stage Staging)\n",
    "model_uri = f\"models:/{model_name}/Staging\"\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "print(f\"Modelo carregado de: {model_uri}\")\n",
    "print(f\"Tipo: {type(loaded_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões\n",
    "sample_data = X_test.iloc[:5]\n",
    "predictions = loaded_model.predict(sample_data)\n",
    "probabilities = loaded_model.predict_proba(sample_data)\n",
    "\n",
    "print(\"\\n=== PREVISÕES DE EXEMPLO ===\")\n",
    "for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "    print(f\"\\nAmostra {i+1}:\")\n",
    "    print(f\"  Classe predita: {iris.target_names[pred]}\")\n",
    "    print(f\"  Probabilidades: {dict(zip(iris.target_names, prob))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Salvando Modelo Localmente\n",
    "\n",
    "### Tarefa 4: Exporte o modelo para uso local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Criar diretório para modelos\n",
    "model_dir = \"/tmp/deployed_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Salvar modelo\n",
    "model_path = os.path.join(model_dir, \"iris_model.pkl\")\n",
    "joblib.dump(loaded_model, model_path)\n",
    "\n",
    "print(f\"Modelo salvo em: {model_path}\")\n",
    "print(f\"Tamanho do arquivo: {os.path.getsize(model_path) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar metadata do modelo\n",
    "metadata = {\n",
    "    \"model_name\": model_name,\n",
    "    \"version\": str(latest_version),\n",
    "    \"features\": list(X.columns),\n",
    "    \"target_names\": list(iris.target_names),\n",
    "    \"training_date\": pd.Timestamp.now().isoformat(),\n",
    "    \"metrics\": {\n",
    "        \"test_accuracy\": float(test_score)\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(model_dir, \"model_metadata.json\")\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nMetadata salvo em: {metadata_path}\")\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Simulação de API de Inferência\n",
    "\n",
    "### Tarefa 5: Crie uma função de inferência simulando uma API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInferenceService:\n",
    "    \"\"\"Serviço de inferência simulando uma API\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, metadata_path):\n",
    "        self.model = joblib.load(model_path)\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        print(f\"Serviço inicializado com modelo versão {self.metadata['version']}\")\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        \"\"\"Fazer previsão\"\"\"\n",
    "        # Validar input\n",
    "        if not isinstance(input_data, pd.DataFrame):\n",
    "            input_data = pd.DataFrame(input_data, columns=self.metadata['features'])\n",
    "        \n",
    "        # Previsão\n",
    "        predictions = self.model.predict(input_data)\n",
    "        probabilities = self.model.predict_proba(input_data)\n",
    "        \n",
    "        # Formatar resposta\n",
    "        results = []\n",
    "        for pred, prob in zip(predictions, probabilities):\n",
    "            results.append({\n",
    "                \"prediction\": self.metadata['target_names'][pred],\n",
    "                \"confidence\": float(prob.max()),\n",
    "                \"probabilities\": {\n",
    "                    name: float(p) \n",
    "                    for name, p in zip(self.metadata['target_names'], prob)\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def health_check(self):\n",
    "        \"\"\"Verificar saúde do serviço\"\"\"\n",
    "        return {\n",
    "            \"status\": \"healthy\",\n",
    "            \"model_name\": self.metadata['model_name'],\n",
    "            \"model_version\": self.metadata['version']\n",
    "        }\n",
    "\n",
    "# Inicializar serviço\n",
    "service = ModelInferenceService(model_path, metadata_path)\n",
    "print(\"\\nServiço de inferência pronto!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar health check\n",
    "health = service.health_check()\n",
    "print(\"Health Check:\")\n",
    "print(json.dumps(health, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar inferência\n",
    "test_input = [\n",
    "    [5.1, 3.5, 1.4, 0.2],  # Setosa\n",
    "    [6.3, 2.9, 5.6, 1.8],  # Virginica\n",
    "    [5.9, 3.0, 4.2, 1.5]   # Versicolor\n",
    "]\n",
    "\n",
    "predictions = service.predict(test_input)\n",
    "\n",
    "print(\"\\n=== RESULTADOS DA INFERÊNCIA ===\")\n",
    "for i, pred in enumerate(predictions, 1):\n",
    "    print(f\"\\nInput {i}:\")\n",
    "    print(json.dumps(pred, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Versionamento e Rollback\n",
    "\n",
    "### Tarefa 6: Simule o deployment de uma nova versão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar nova versão do modelo\n",
    "with mlflow.start_run(run_name=\"production_model_v2\") as run:\n",
    "    # Pipeline com parâmetros diferentes\n",
    "    pipeline_v2 = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    pipeline_v2.fit(X_train, y_train)\n",
    "    test_score_v2 = pipeline_v2.score(X_test, y_test)\n",
    "    \n",
    "    # Registrar modelo\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline_v2,\n",
    "        \"model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Nova versão treinada!\")\n",
    "    print(f\"Test Accuracy v2: {test_score_v2:.4f}\")\n",
    "    print(f\"Test Accuracy v1: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar versões\n",
    "versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "print(\"\\n=== VERSÕES DO MODELO ===\")\n",
    "for v in sorted(versions, key=lambda x: int(x.version), reverse=True):\n",
    "    print(f\"Versão {v.version}:\")\n",
    "    print(f\"  Stage: {v.current_stage}\")\n",
    "    print(f\"  Status: {v.status}\")\n",
    "    print(f\"  Run ID: {v.run_id}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Promovendo para Produção\n",
    "\n",
    "### Tarefa 7: Promova o melhor modelo para produção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promover versão atual para produção\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=latest_version,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True\n",
    ")\n",
    "\n",
    "print(f\"Modelo versão {latest_version} promovido para Production\")\n",
    "print(\"Versões anteriores arquivadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo de produção\n",
    "production_model = mlflow.sklearn.load_model(f\"models:/{model_name}/Production\")\n",
    "\n",
    "print(\"Modelo de produção carregado com sucesso!\")\n",
    "print(f\"Accuracy no teste: {production_model.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Estratégias de Deployment\n",
    "\n",
    "### Conceitos Importantes:\n",
    "\n",
    "#### Blue-Green Deployment\n",
    "- Manter dois ambientes (azul e verde)\n",
    "- Trocar tráfego instantaneamente\n",
    "- Rollback rápido se necessário\n",
    "\n",
    "#### Canary Deployment\n",
    "- Liberar gradualmente para um subconjunto de usuários\n",
    "- Monitorar performance\n",
    "- Aumentar tráfego progressivamente\n",
    "\n",
    "#### Shadow Deployment\n",
    "- Executar novo modelo em paralelo\n",
    "- Não afetar usuários\n",
    "- Comparar resultados antes de trocar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulação de Canary Deployment\n",
    "class CanaryDeployment:\n",
    "    def __init__(self, model_current, model_canary, canary_percentage=10):\n",
    "        self.model_current = model_current\n",
    "        self.model_canary = model_canary\n",
    "        self.canary_percentage = canary_percentage\n",
    "        self.requests_count = 0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.requests_count += 1\n",
    "        \n",
    "        # Decidir qual modelo usar\n",
    "        if np.random.rand() * 100 < self.canary_percentage:\n",
    "            model_used = \"canary\"\n",
    "            prediction = self.model_canary.predict(X)\n",
    "        else:\n",
    "            model_used = \"current\"\n",
    "            prediction = self.model_current.predict(X)\n",
    "        \n",
    "        return prediction, model_used\n",
    "\n",
    "# Simular canary deployment\n",
    "canary = CanaryDeployment(loaded_model, production_model, canary_percentage=20)\n",
    "\n",
    "print(\"\\n=== SIMULAÇÃO DE CANARY DEPLOYMENT (20%) ===\")\n",
    "canary_count = 0\n",
    "current_count = 0\n",
    "\n",
    "for i in range(100):\n",
    "    sample = X_test.iloc[[i % len(X_test)]]\n",
    "    pred, model_used = canary.predict(sample)\n",
    "    if model_used == \"canary\":\n",
    "        canary_count += 1\n",
    "    else:\n",
    "        current_count += 1\n",
    "\n",
    "print(f\"Requests para modelo atual: {current_count}\")\n",
    "print(f\"Requests para modelo canary: {canary_count}\")\n",
    "print(f\"Porcentagem canary: {canary_count}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercícios Adicionais\n",
    "\n",
    "### Desafios para Praticar:\n",
    "\n",
    "1. **MLFlow Model Serving**: Inicie o MLFlow model serving localmente:\n",
    "   ```bash\n",
    "   mlflow models serve -m models:/iris_classifier/Production -p 5001\n",
    "   ```\n",
    "\n",
    "2. **API REST**: Crie requests para o endpoint do MLFlow:\n",
    "   ```python\n",
    "   import requests\n",
    "   data = {\"instances\": [[5.1, 3.5, 1.4, 0.2]]}\n",
    "   response = requests.post(\"http://localhost:5001/invocations\", json=data)\n",
    "   ```\n",
    "\n",
    "3. **Docker**: Crie uma imagem Docker do modelo\n",
    "4. **A/B Testing**: Implemente lógica de A/B testing entre modelos\n",
    "5. **Batch Inference**: Crie pipeline para inferência em lote\n",
    "6. **Feature Store**: Simule integração com feature store\n",
    "\n",
    "### Questões para Reflexão:\n",
    "\n",
    "1. Qual estratégia de deployment é mais adequada para seu caso de uso?\n",
    "2. Como você garantiria zero downtime durante o deployment?\n",
    "3. Quais métricas você monitoraria em produção?\n",
    "4. Como você implementaria rollback automático?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
